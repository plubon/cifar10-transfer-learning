{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "\n",
    "def get_resized_image(filename, height, width):\n",
    "    img = np.load(os.path.join('data','images',filename+'.npy'))\n",
    "    return resize(img, (height, width), anti_aliasing=False, mode='constant')\n",
    "\n",
    "if not os.path.exists(os.path.join('data','features')):\n",
    "    os.makedirs(os.path.join('data','features'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception v3 model is used to extract feature - values of last layer before last softmax layer are computed, as suggested by authors of the model.\n",
    "\n",
    "Images are resized to conform with model input size.\n",
    "\n",
    "Small batch size is selected due to memory restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number: 0\n",
      "Batch number: 3000\n",
      "Batch number: 6000\n",
      "Batch number: 9000\n",
      "Batch number: 12000\n",
      "Batch number: 15000\n",
      "Batch number: 18000\n",
      "Batch number: 21000\n",
      "Batch number: 24000\n",
      "Batch number: 27000\n",
      "Batch number: 30000\n",
      "Batch number: 33000\n",
      "Batch number: 36000\n",
      "Batch number: 39000\n",
      "Batch number: 42000\n",
      "Batch number: 45000\n",
      "Batch number: 48000\n",
      "Batch number: 51000\n",
      "Batch number: 54000\n",
      "Batch number: 57000\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    module = hub.Module(\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1\")\n",
    "    height, width = hub.get_expected_image_size(module)\n",
    "    index = pd.read_csv(os.path.join('data', 'index.csv'))\n",
    "    input_tensor = tf.placeholder(tf.float32, [None, height, width, 3])\n",
    "    output_tensor = module(input_tensor)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        for i in range(0, index.shape[0], BATCH_SIZE):\n",
    "            batch = []\n",
    "            filenames = []\n",
    "            for j in range(i, i + BATCH_SIZE):\n",
    "                batch.append(get_resized_image(index['filename'].loc[j], height, width))\n",
    "                filenames.append(index['filename'].loc[j])\n",
    "            features = sess.run(output_tensor,{input_tensor:np.stack(batch, axis=0)})\n",
    "            for j in range(BATCH_SIZE):\n",
    "                cnn_code = features[j,:]\n",
    "                np.save(os.path.join('data','features',filenames[j]+'.npy'),cnn_code)\n",
    "            if i % 3000 == 0:\n",
    "                print(\"Batch number: {}\".format(str(i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
